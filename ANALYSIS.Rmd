---
title: "Analysis"
output: pdf_document
---

```{r}
spotify$genre <- factor(spotify$genre)
spotify$genre <- relevel(spotify$genre, ref= "Classical")
```

```{r}
topten_spotify <- spotify %>%
  group_by(genre) %>% 
  summarise(counts=n()) %>%
  top_n(10)
spotify.top <- spotify %>%
  filter(genre == topten_spotify$genre) %>%
  select(genre, popularity, acousticness, danceability, duration_ms, energy, instrumentalness, liveness, loudness, speechiness, tempo, valence)
spotify.top$genre <- droplevels(spotify.top$genre)
```


```{r}
n <- nrow(spotify.top)
sample.size <- floor(.3 * n)
set.seed(1)
rows <- sample(seq_len(n), size = sample.size)
train <- spotify.top[rows,] 
test <- spotify.top[-rows,]
```

```{r}
library(nnet)
model1 <- multinom(genre ~ danceability, data = train)
summary(model1)
```

```{r}
model.all <- multinom(genre ~ ., data = train)
step_model <- step(model.all, direction = "forward")
summary(step_model)
```
```{r}
#exponentiated coefficients
exp(coef(step_model))
```
```{r}
head(probability.table <- fitted(step_model))

# Predicting the values for train dataset
train$predicted <- predict(step_model, newdata = train, "class")
 
# Building classification table
ctable <- table(train$genre, train$predicted)
 
# Calculating accuracy - sum of diagonal elements divided by total obs
round((sum(diag(ctable))/sum(ctable))*100,2)
```

Ok so 13% accuracy kinda sucks lmaoooooo

so lets do the top 5 for kickers

```{r}
topfive_spotify <- spotify %>%
  group_by(genre) %>% 
  summarise(counts=n()) %>%
  top_n(5)
spotify.top5 <- spotify %>%
  filter(genre == topfive_spotify$genre) %>%
  select(genre, popularity, acousticness, danceability, duration_ms, energy, instrumentalness, liveness, loudness, speechiness, tempo, valence)
spotify.top5$genre <- droplevels(spotify.top5$genre)
```
```{r}
n <- nrow(spotify.top5)
sample.size <- floor(.3 * n)
set.seed(1)
rows <- sample(seq_len(n), size = sample.size)
train5 <- spotify.top5[rows,] 
test5 <- spotify.top5[-rows,]
```

```{r}
model.all5 <- multinom(genre ~ ., data = train5)
step_model5 <- step(model.all5, direction = "forward")
summary(step_model5)
```
#AIC is lower nice

```{r}
head(probability.table <- fitted(step_model5))

# Predicting the values for train dataset
train5$predicted5 <- predict(step_model5, newdata = train5, "class")
 
# Building classification table
ctable5 <- table(train5$genre, train5$predicted5)
 
# Calculating accuracy - sum of diagonal elements divided by total obs
round((sum(diag(ctable5))/sum(ctable5))*100,2)
```
yooooo 75% not too shabby lets see on the fucking test boi 
```{r}

# Predicting the values for train dataset
test5$predicted5 <- predict(step_model5, newdata = test5, "class")
 
# Building classification table
ctable5.test <- table(test5$genre, test5$predicted5)

# Calculating accuracy - sum of diagonal elements divided by total obs
round((sum(diag(ctable5.test))/sum(ctable5.test))*100,2)

```
litttyyyyyy.

# SVM

```{r}
# install.packages('e1071')
library(e1071)
library(caret)
```


```{r}
svm_model1 <- svm(genre ~ . - liveness, data=train5, cost = .1, kernel='radial')
summary(svm_model1)

preds <- predict(svm_model1, newdata=test5)
svm.table <- table(preds, test5$predicted5)
round((sum(diag(svm.table))/sum(svm.table))*100,2)
```
```{r}
tune.out=tune(svm,genre ~ . -liveness,data=train5 , ranges =list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100) ))

summary (tune.out)
```




```{r ROC}

#svmfit.opt <- svm(genre ~ . -liveness,data=train5, kernel = "radial", gamma = 2, cost = 10, decision.values = TRUE)
#fitted <- attributes(predict(svmfit.opt, train5,decision.values=TRUE))$decision.values

#library(pROC)
#ROC_svm <- roc(spotify[train5, "genre"], fitted)
#plot(ROC_svm)

```



